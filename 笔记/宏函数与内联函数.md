# C++ 宏函数与内联函数详解

## 目录
- [宏函数 (Macro Functions)](#宏函数-macro-functions)
- [内联函数 (Inline Functions)](#内联函数-inline-functions)
- [宏函数 vs 内联函数](#宏函数-vs-内联函数)
- [在CUDA中的应用](#在cuda中的应用)

---

## 宏函数 (Macro Functions)

### 定义与语法

宏函数是通过预处理器指令 `#define` 定义的代码片段，在编译前进行**文本替换**。

```cpp
// 基本语法
#define 宏名(参数列表) 替换文本

// 示例
#define SQUARE(x) ((x) * (x))
#define MAX(a, b) ((a) > (b) ? (a) : (b))
#define MIN(a, b) ((a) < (b) ? (a) : (b))
```

### 关键特性

#### 1. 文本替换机制
```cpp
#define SQUARE(x) ((x) * (x))

int a = 5;
int result = SQUARE(a + 1);  
// 预处理后展开为: ((a + 1) * (a + 1))
// 结果: 36
```

#### 2. 多行宏定义
使用反斜杠 `\` 进行换行：
```cpp
#define SWAP(a, b, type) \
    do { \
        type temp = a; \
        a = b; \
        b = temp; \
    } while(0)
```

> [!TIP]
> 使用 `do { ... } while(0)` 包装多语句宏，确保宏在各种上下文中都能正确工作，避免分号和控制流问题。

#### 3. 常用的宏技巧

**字符串化操作符 (#)**
```cpp
#define TO_STRING(x) #x
TO_STRING(hello)  // 展开为 "hello"
```

**连接操作符 (##)**
```cpp
#define CONCAT(a, b) a##b
CONCAT(var, 123)  // 展开为 var123
```

**可变参数宏**
```cpp
#define LOG(format, ...) printf(format, ##__VA_ARGS__)
LOG("Error: %d\n", errorCode);
LOG("Success!");
```

### 优点

1. **无函数调用开销** - 直接文本替换，没有栈操作
2. **类型无关** - 可以用于任何类型（类似模板）
3. **编译时计算** - 某些情况下可以在编译时完成计算
4. **条件编译** - 可以配合 `#ifdef` 等进行条件编译

```cpp
#define DEBUG_MODE

#ifdef DEBUG_MODE
    #define DEBUG_PRINT(x) printf("Debug: %s\n", x)
#else
    #define DEBUG_PRINT(x)
#endif
```

### 缺点

> [!CAUTION]
> 宏函数存在多个陷阱，使用时需要特别小心！

#### 1. 缺乏类型检查
```cpp
#define SQUARE(x) ((x) * (x))

SQUARE("hello");  // 编译时可能产生奇怪的错误，而非清晰的类型错误
```

#### 2. 参数副作用问题
```cpp
#define SQUARE(x) ((x) * (x))

int i = 5;
int result = SQUARE(i++);  
// 展开为: ((i++) * (i++))
// i 会被递增两次！结果不可预测
```

#### 3. 难以调试
- 调试器无法单步进入宏
- 错误信息指向展开后的代码，不是宏定义处
- 预处理展开可能产生难以理解的错误信息

#### 4. 命名空间污染
宏不遵守作用域规则，可能导致命名冲突：
```cpp
#define MAX(a, b) ((a) > (b) ? (a) : (b))
// 可能与标准库或其他代码中的 MAX 冲突
```

### 最佳实践

```cpp
// ✓ 好的做法：使用括号保护参数和整个表达式
#define SQUARE(x) ((x) * (x))

// ✗ 坏的做法：缺少括号
#define SQUARE_BAD(x) x * x
// SQUARE_BAD(1 + 2) 会展开为 1 + 2 * 1 + 2 = 5，而非 9

// ✓ 好的做法：使用大写字母命名宏
#define MAX_BUFFER_SIZE 1024

// ✓ 好的做法：多语句宏使用 do-while(0)
#define FREE_AND_NULL(ptr) \
    do { \
        free(ptr); \
        ptr = NULL; \
    } while(0)
```

---

## 内联函数 (Inline Functions)

### 定义与语法

内联函数使用 `inline` 关键字声明，建议编译器将函数体直接插入调用点，避免函数调用开销。

```cpp
// 基本语法
inline 返回类型 函数名(参数列表) {
    // 函数体
}

// 示例
inline int square(int x) {
    return x * x;
}

inline int max(int a, int b) {
    return a > b ? a : b;
}
```

### 关键特性

#### 1. 编译器建议而非强制
```cpp
inline void complexFunction() {
    // 即使声明为 inline，编译器可能选择不内联
    // 如果函数体过大或包含递归、循环等
    for (int i = 0; i < 1000; i++) {
        // ... 复杂逻辑
    }
}
```

#### 2. 类内定义自动内联
```cpp
class MyClass {
    // 类内定义的函数默认是内联的
    int getValue() const { return value; }
    
private:
    int value;
};
```

#### 3. 模板函数通常是内联的
```cpp
template<typename T>
inline T max(T a, T b) {
    return a > b ? a : b;
}
```

### 优点

1. **类型安全** - 参数和返回值有类型检查
2. **作用域规则** - 遵守C++的作用域和命名空间规则
3. **可调试性** - 可以设置断点，单步调试
4. **无副作用问题** - 参数只计算一次
5. **性能优化** - 消除函数调用开销（栈操作、跳转等）

```cpp
inline int square(int x) {
    return x * x;
}

int i = 5;
int result = square(i++);  // i 只递增一次，结果确定
// 等价于：int result = (i++) * (i++)  // 这是错的
// 实际是：int temp = i++; int result = temp * temp;
```

### 缺点

1. **代码膨胀** - 每个调用点都插入函数体，可能增加可执行文件大小
2. **编译时间增加** - 需要在头文件中定义，改动后需重新编译所有使用者
3. **编译器决定权** - `inline` 只是建议，编译器可能忽略

### 何时使用内联函数

✓ **适合内联的情况：**
- 函数体很小（通常1-5行）
- 频繁调用的函数
- 性能关键路径上的简单函数
- getter/setter 访问器

```cpp
class Vector3 {
    float x, y, z;
public:
    inline float getX() const { return x; }
    inline float getY() const { return y; }
    inline float getZ() const { return z; }
    
    inline float dot(const Vector3& other) const {
        return x * other.x + y * other.y + z * other.z;
    }
};
```

✗ **不适合内联的情况：**
- 函数体较大
- 包含循环或递归
- 函数地址被使用
- 虚函数（通常无法内联）

---

## 宏函数 vs 内联函数

| 特性 | 宏函数 | 内联函数 |
|------|--------|----------|
| **实现机制** | 预处理器文本替换 | 编译器代码插入 |
| **类型检查** | ✗ 无 | ✓ 有 |
| **调试** | ✗ 困难 | ✓ 容易 |
| **作用域** | ✗ 无作用域 | ✓ 遵守C++作用域规则 |
| **副作用** | ✗ 可能多次求值参数 | ✓ 参数只求值一次 |
| **类型无关性** | ✓ 可用于任何类型 | ✗ 需要模板实现泛型 |
| **代码大小** | 可能增加 | 可能增加 |
| **条件编译** | ✓ 支持 | ✗ 不支持 |
| **强制性** | ✓ 总是替换 | ✗ 编译器可选择不内联 |

### 何时选择宏函数？

```cpp
// 1. 需要条件编译
#ifdef _DEBUG
    #define ASSERT(condition) if(!(condition)) abort()
#else
    #define ASSERT(condition)
#endif

// 2. 需要字符串化或连接
#define TRACE(var) printf(#var " = %d\n", var)

// 3. 简单的常量定义
#define PI 3.14159265359
#define MAX_SIZE 1024
```

### 何时选择内联函数？

```cpp
// 1. 需要类型安全的场景
inline float calculateArea(float radius) {
    return 3.14159f * radius * radius;
}

// 2. 类的简单成员函数
class Point {
    int x, y;
public:
    inline int getX() const { return x; }
    inline void setX(int newX) { x = newX; }
};

// 3. 模板函数
template<typename T>
inline T clamp(T value, T min, T max) {
    return value < min ? min : (value > max ? max : value);
}
```

> [!IMPORTANT]
> **现代C++建议**：优先使用内联函数而非宏函数，除非有特定需求（如条件编译）。C++11之后，`constexpr` 函数也是很好的选择。

---

## 在CUDA中的应用

### 1. CUDA中的宏定义

CUDA编程中大量使用宏来提高代码可读性和可维护性：

#### 常用的CUDA宏

```cpp
// 错误检查宏
#define CUDA_CHECK(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            fprintf(stderr, "CUDA Error at %s:%d: %s\n", \
                    __FILE__, __LINE__, cudaGetErrorString(err)); \
            exit(EXIT_FAILURE); \
        } \
    } while(0)

// 使用示例
CUDA_CHECK(cudaMalloc(&d_data, size));
CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));
```

#### 线程索引计算宏
```cpp
// 1D 线程索引
#define GET_GLOBAL_ID_1D() (blockIdx.x * blockDim.x + threadIdx.x)

// 2D 线程索引
#define GET_GLOBAL_ID_2D_X() (blockIdx.x * blockDim.x + threadIdx.x)
#define GET_GLOBAL_ID_2D_Y() (blockIdx.y * blockDim.y + threadIdx.y)

// 3D 线程索引
#define GET_GLOBAL_ID_3D_X() (blockIdx.x * blockDim.x + threadIdx.x)
#define GET_GLOBAL_ID_3D_Y() (blockIdx.y * blockDim.y + threadIdx.y)
#define GET_GLOBAL_ID_3D_Z() (blockIdx.z * blockDim.z + threadIdx.z)
```

#### 网格和块配置宏
```cpp
// 计算所需的块数量
#define GET_BLOCKS(n, threads) (((n) + (threads) - 1) / (threads))

// 使用示例
int threadsPerBlock = 256;
int blocksPerGrid = GET_BLOCKS(dataSize, threadsPerBlock);
kernel<<<blocksPerGrid, threadsPerBlock>>>(data, dataSize);
```

#### 数学和工具宏
```cpp
#define MIN(a, b) ((a) < (b) ? (a) : (b))
#define MAX(a, b) ((a) > (b) ? (a) : (b))
#define CLAMP(x, min, max) (MIN(MAX(x, min), max))
#define SWAP(a, b, T) do { T tmp = a; a = b; b = tmp; } while(0)

// 对齐宏
#define ALIGN_UP(x, align) (((x) + (align) - 1) & ~((align) - 1))
```

### 2. CUDA中的内联函数

#### Device函数内联

CUDA中的 `__device__` 函数可以使用 `__inline__` 或 `__forceinline__` 修饰符：

```cpp
// __inline__: 建议编译器内联
__device__ __inline__ float square(float x) {
    return x * x;
}

// __forceinline__: 强制编译器内联
__device__ __forceinline__ float dot(float3 a, float3 b) {
    return a.x * b.x + a.y * b.y + a.z * b.z;
}

// 在kernel中使用
__global__ void vectorNorm(float3* vectors, float* norms, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        float3 v = vectors[idx];
        norms[idx] = sqrtf(dot(v, v));  // 内联调用
    }
}
```

#### Host-Device函数

函数可以同时在主机和设备上使用：

```cpp
__host__ __device__ __forceinline__ float lerp(float a, float b, float t) {
    return a + t * (b - a);
}

// 可以在host代码和device kernel中都使用
__global__ void interpolateKernel(float* in1, float* in2, float* out, float t, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        out[idx] = lerp(in1[idx], in2[idx], t);
    }
}
```

### 3. 实际应用示例

#### 示例1：向量加法优化

```cpp
// 使用宏进行错误检查和配置
#define CUDA_CHECK(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            fprintf(stderr, "CUDA Error: %s\n", cudaGetErrorString(err)); \
            exit(EXIT_FAILURE); \
        } \
    } while(0)

#define THREADS_PER_BLOCK 256
#define GET_BLOCKS(n) (((n) + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK)

// 使用内联设备函数进行向量运算
__device__ __forceinline__ float3 add(float3 a, float3 b) {
    return make_float3(a.x + b.x, a.y + b.y, a.z + b.z);
}

__device__ __forceinline__ float3 scale(float3 v, float s) {
    return make_float3(v.x * s, v.y * s, v.z * s);
}

__global__ void vectorAddScaleKernel(float3* a, float3* b, float3* result, 
                                      float scale_factor, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        float3 sum = add(a[idx], b[idx]);
        result[idx] = scale(sum, scale_factor);
    }
}

void vectorOperations(float3* d_a, float3* d_b, float3* d_result, int n) {
    int blocks = GET_BLOCKS(n);
    vectorAddScaleKernel<<<blocks, THREADS_PER_BLOCK>>>(d_a, d_b, d_result, 2.0f, n);
    CUDA_CHECK(cudaGetLastError());
    CUDA_CHECK(cudaDeviceSynchronize());
}
```

#### 示例2：矩阵运算辅助函数

```cpp
// 数学常量宏
#define PI 3.14159265359f
#define TWO_PI 6.28318530718f
#define EPSILON 1e-6f

// 内联数学函数
__device__ __forceinline__ float clamp(float x, float min_val, float max_val) {
    return fminf(fmaxf(x, min_val), max_val);
}

__device__ __forceinline__ float saturate(float x) {
    return clamp(x, 0.0f, 1.0f);
}

__device__ __forceinline__ bool floatEqual(float a, float b) {
    return fabsf(a - b) < EPSILON;
}

// 2D索引转换宏
#define IDX2D(i, j, width) ((i) * (width) + (j))

__global__ void normalizeMatrixKernel(float* matrix, int rows, int cols) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < rows && col < cols) {
        int idx = IDX2D(row, col, cols);
        matrix[idx] = saturate(matrix[idx]);  // 限制在[0, 1]范围
    }
}
```

#### 示例3：性能关键的内联函数

```cpp
// 快速原子操作封装
__device__ __forceinline__ float atomicAddFloat(float* address, float val) {
    return atomicAdd(address, val);
}

// Warp级别的reduce操作
__device__ __forceinline__ float warpReduceSum(float val) {
    for (int offset = warpSize / 2; offset > 0; offset /= 2) {
        val += __shfl_down_sync(0xffffffff, val, offset);
    }
    return val;
}

// 块级别的reduce
__device__ __forceinline__ float blockReduceSum(float val) {
    __shared__ float shared[32];  // 每个warp一个元素
    int lane = threadIdx.x % warpSize;
    int wid = threadIdx.x / warpSize;
    
    val = warpReduceSum(val);
    
    if (lane == 0) shared[wid] = val;
    __syncthreads();
    
    val = (threadIdx.x < blockDim.x / warpSize) ? shared[lane] : 0.0f;
    if (wid == 0) val = warpReduceSum(val);
    
    return val;
}

__global__ void sumReductionKernel(float* input, float* output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    float val = (idx < n) ? input[idx] : 0.0f;
    
    val = blockReduceSum(val);
    
    if (threadIdx.x == 0) {
        atomicAddFloat(output, val);
    }
}
```

### 4. CUDA中的宏与内联函数选择指南

#### 使用宏的场景

```cpp
// ✓ 错误检查和调试
#define CUDA_CHECK(call) /* ... */

// ✓ 条件编译
#ifdef __CUDA_ARCH__
    #define IS_DEVICE 1
#else
    #define IS_DEVICE 0
#endif

// ✓ 常量定义
#define WARP_SIZE 32
#define MAX_THREADS_PER_BLOCK 1024

// ✓ 简单的计算和索引
#define GET_GLOBAL_ID() (blockIdx.x * blockDim.x + threadIdx.x)
```

#### 使用内联函数的场景

```cpp
// ✓ 复杂的数学运算
__device__ __forceinline__ float3 cross(float3 a, float3 b) {
    return make_float3(
        a.y * b.z - a.z * b.y,
        a.z * b.x - a.x * b.z,
        a.x * b.y - a.y * b.x
    );
}

// ✓ 需要类型安全的函数
template<typename T>
__device__ __forceinline__ T max3(T a, T b, T c) {
    return max(a, max(b, c));
}

// ✓ 性能关键的小函数
__device__ __forceinline__ int divUp(int a, int b) {
    return (a + b - 1) / b;
}
```

### 5. 最佳实践总结

> [!IMPORTANT]
> **CUDA性能优化建议**

1. **使用 `__forceinline__` 标记性能关键路径上的小函数**
   ```cpp
   __device__ __forceinline__ float fastFunction() { /* ... */ }
   ```

2. **宏用于编译时常量和简单配置**
   ```cpp
   #define TILE_SIZE 16
   ```

3. **避免在设备代码中使用递归和大函数体**
   - 会阻止内联优化
   - 增加寄存器压力

4. **使用模板而非宏实现泛型设备函数**
   ```cpp
   template<typename T>
   __device__ __forceinline__ T atomicAddGeneric(T* addr, T val) {
       // 类型安全的原子操作
   }
   ```

5. **利用编译器优化选项**
   ```bash
   nvcc -O3 --use_fast_math -arch=sm_80 kernel.cu
   ```

---

## 总结

### C++环境选择
- **宏函数**：条件编译、字符串化、简单常量
- **内联函数**：类型安全、可调试的性能优化

### CUDA环境选择
- **宏**：错误检查、配置参数、索引计算
- **`__forceinline__`**：设备函数优化、数学运算
- **模板 + 内联**：类型安全的泛型设备代码

> [!TIP]
> 现代编译器（包括nvcc）非常智能，通常能自动内联合适的函数。显式使用 `inline` 或 `__forceinline__` 主要用于关键性能路径。

记住：**清晰的代码 > 过早的优化**。先编写正确、可读的代码，然后在性能分析（profiling）指导下优化。
